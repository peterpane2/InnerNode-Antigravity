"""
agent_brain.py â€” ë¸Œë¦¿ì§€ ì—ì´ì „íŠ¸ (v3.4)
- 125% DPI ë°°ìœ¨ ë° ë§ˆìš°ìŠ¤ ì¢Œí‘œ ìµœì¢… ë³´ì • ì™„ë£Œ
- DEBUG_IMAGE í† ê¸€ ì¶”ê°€ (ê¸°ë³¸ False)
- ì´ë¯¸ì§€ ê¸°ë°˜ ë²„íŠ¼ í´ë¦­ ì§€ì› (icon_*.png)
- /auto: ì‹¤ì‹œê°„ ìë™ ì•„ì´ì½˜ ê°ì‹œ & í´ë¦­
"""
import os, json, time, threading, tempfile, ctypes, requests
import pyautogui, pyperclip, win32gui, win32con
import numpy as np
from PIL import Image
from io import BytesIO
from dotenv import load_dotenv

try:
    from scipy import ndimage
except ImportError:
    ndimage = None

# ğŸ› ï¸ ë””ë²„ê·¸ ì„¤ì •: í´ë¦­ ì§€ì ì„ ì‚¬ì§„ìœ¼ë¡œ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œë§Œ Trueë¡œ ë³€ê²½í•˜ì„¸ìš”.
DEBUG_IMAGE = False

# DPI Awareness ì„¤ì • (125% ë°°ìœ¨ ë“± ëŒ€ì‘)
try:
    ctypes.windll.shcore.SetProcessDpiAwareness(1)
except:
    try: ctypes.windll.user32.SetProcessDPIAware()
    except: pass

load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "0")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MAILBOX_PATH = os.path.join(BASE_DIR, "mailbox.json")

def read_mailbox():
    try:
        with open(MAILBOX_PATH, "r", encoding="utf-8") as f: return json.load(f)
    except: return {"inbound": [], "outbound": [], "approval_request": None}

def write_mailbox(box):
    fd, tmp = tempfile.mkstemp(dir=BASE_DIR, suffix=".tmp")
    with os.fdopen(fd, "w", encoding="utf-8") as f: json.dump(box, f, ensure_ascii=False, indent=2)
    os.replace(tmp, MAILBOX_PATH)

def push_msg(msg: str):
    if not BOT_TOKEN: return
    try: requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage", 
                      json={"chat_id": int(CHAT_ID), "text": msg}, timeout=5)
    except: pass

def push_img(img_obj, caption=""):
    if not BOT_TOKEN or not DEBUG_IMAGE: return
    try:
        buf = BytesIO()
        img_obj.save(buf, format="PNG")
        buf.seek(0)
        requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto", 
                      files={'photo': buf}, data={'chat_id': int(CHAT_ID), 'caption': caption}, timeout=10)
    except: pass

def get_vscode_window_rect():
    found = []
    win32gui.EnumWindows(lambda hwnd, res: res.append((hwnd, win32gui.GetWindowText(hwnd))) if win32gui.IsWindowVisible(hwnd) else None, found)
    target = None
    for hwnd, title in found:
        class_name = win32gui.GetClassName(hwnd)
        if class_name == "Chrome_WidgetWin_1" and any(x in title for x in ["Visual Studio Code", "Antigravity", "OpenClaw"]):
            if not any(title.endswith(x) for x in [" - Chrome", " - Microsoft Edge"]):
                target = (hwnd, title)
                break
    if not target: return None, None, None
    hwnd, title = target
    placement = win32gui.GetWindowPlacement(hwnd)
    if placement[1] == win32con.SW_SHOWMINIMIZED: win32gui.ShowWindow(hwnd, win32con.SW_RESTORE)
    else: win32gui.ShowWindow(hwnd, win32con.SW_SHOW)
    try: win32gui.SetForegroundWindow(hwnd)
    except: pass
    time.sleep(0.5)
    rect = win32gui.GetWindowRect(hwnd)
    return hwnd, rect, title

# â”€â”€ ì´ë¯¸ì§€ ê¸°ë°˜ ë²„íŠ¼ í´ë¦­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ICON_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".instruction")

def click_icon(icon_name: str, confidence: float = 0.8, timeout: float = 0.0) -> bool:
    """í™”ë©´ì—ì„œ ì•„ì´ì½˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•„ í´ë¦­í•©ë‹ˆë‹¤.
    timeout > 0 ì´ë©´ í•´ë‹¹ ì´ˆë§Œí¼ ë°˜ë³µ íƒìƒ‰í•©ë‹ˆë‹¤.
    """
    icon_path = os.path.join(ICON_DIR, f"icon_{icon_name}.png")
    if not os.path.exists(icon_path):
        push_msg(f"âš ï¸ ì•„ì´ì½˜ íŒŒì¼ ì—†ìŒ: icon_{icon_name}.png")
        return False

    deadline = time.time() + max(timeout, 0)
    while True:
        try:
            pos = pyautogui.locateCenterOnScreen(icon_path, confidence=confidence)
            if pos:
                pyautogui.moveTo(pos, duration=0.2)
                pyautogui.click()
                return True
        except Exception:
            pass  # opencv ë¯¸ì„¤ì¹˜ ë“± â€” ì•„ë˜ì„œ ë³„ë„ ì•ˆë‚´
        if time.time() >= deadline:
            break
        time.sleep(0.5)
    return False


def type_into_chatwindow(text: str) -> bool:
    """ì±„íŒ… ì…ë ¥ì°½ì— í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê³  â†’ ë²„íŠ¼(proceed)ì„ í´ë¦­í•©ë‹ˆë‹¤.
    ì¼ë°˜ í…ìŠ¤íŠ¸ ì…ë ¥ê³¼ ë™ì¼í•œ ì¢Œí‘œ(0.88, 0.927)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."""

    # 1. VS Code ì°½ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    hwnd, rect, title = get_vscode_window_rect()
    if not rect:
        push_msg("âŒ VS Code ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    l, t, r, b = rect
    w, h = r - l, b - t

    # 2. ì±„íŒ… ì…ë ¥ì°½ í´ë¦­ (ì¼ë°˜ í…ìŠ¤íŠ¸ì™€ ë™ì¼í•œ ì¢Œí‘œ â€” ì´ë¯¸ ê²€ì¦ë¨)
    click_x = int(l + w * 0.88)
    click_y = int(t + h * 0.927)
    pyautogui.moveTo(click_x, click_y, duration=0.2)
    pyautogui.click()
    time.sleep(0.1)
    pyautogui.click()
    time.sleep(0.3)

    # 3. í…ìŠ¤íŠ¸ ì…ë ¥
    pyperclip.copy(text)
    pyautogui.hotkey("ctrl", "a")
    time.sleep(0.1)
    pyautogui.press("backspace")
    time.sleep(0.1)
    pyautogui.hotkey("ctrl", "v")
    time.sleep(0.3)

    # 4. â†’ (proceed) ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ì „ì†¡
    if not click_icon("proceed", confidence=0.8):
        # proceed ëª» ì°¾ìœ¼ë©´ Enterë¡œ ì „ì†¡ ì‹œë„
        pyautogui.press("enter")
        push_msg("âš ï¸ â†’ ë²„íŠ¼ ëª» ì°¾ì•„ì„œ Enterë¡œ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.")

    return True


def execute_brain_task(command: str) -> bool:
    global _auto_watch_active

    # 0. VS Code ì—†ì´ë„ ì²˜ë¦¬ ê°€ëŠ¥í•œ ëª…ë ¹ì–´ (Auto Watch ë“±)
    if command.startswith("__COMMAND:"):
        clean_command = command[:-2] if command.endswith("__") else command
        parts = clean_command.split(":")
        cmd_type = parts[1]

        if cmd_type == "AUTO_WATCH_ON":
            _auto_watch_active = True
            push_msg("ğŸ¤– Auto Watch ON: accept_all / proceed / run / scrolldown ê°ì‹œ ì‹œì‘!")
            return True

        elif cmd_type == "AUTO_WATCH_OFF":
            _auto_watch_active = False
            push_msg("â¹ï¸ Auto Watch OFF: ìë™ ê°ì‹œ ì¤‘ë‹¨")
            return True

    # 1. VS Code ì°½ í•„ìš”í•œ ëª…ë ¹ì–´
    hwnd, rect, title = get_vscode_window_rect()
    if not rect:
        push_msg("âŒ VS Code ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    l, t, r, b = rect
    w, h = r - l, b - t

    # 2. ì‹œìŠ¤í…œ ëª…ë ¹ì–´ ì²˜ë¦¬ (ë§¤í¬ë¡œ)
    if command.startswith("__COMMAND:"):
        clean_command = command[:-2] if command.endswith("__") else command
        parts = clean_command.split(":")
        cmd_type = parts[1]
        
        if cmd_type == "SCROLL":
            direction = parts[2]
            scroll_x = int(l + w * 0.85)
            scroll_y = int(t + h * 0.5)
            pyautogui.moveTo(scroll_x, scroll_y)
            amount = 800 if direction == "UP" else -800
            pyautogui.scroll(amount)
            return True
        
        elif cmd_type == "CLICK":
            target_x, target_y = int(parts[2]), int(parts[3])
            pyautogui.moveTo(target_x, target_y, duration=0.5)
            pyautogui.click()
            return True

        elif cmd_type == "CLICK_RUN_ONCE":
            btn_x = int(l + w * 0.78) 
            btn_y = int(t + h * 0.88)
            pyautogui.moveTo(btn_x, btn_y, duration=0.5)
            pyautogui.click()
            return True

        elif cmd_type == "CLICK_RUN_ALL":
            btn_x = int(l + w * 0.85) 
            btn_y = int(t + h * 0.88)
            pyautogui.moveTo(btn_x, btn_y, duration=0.5)
            pyautogui.click()
            return True

        elif cmd_type == "ICON":
            icon_name = parts[2] if len(parts) > 2 else ""
            if not icon_name:
                push_msg("âŒ ICON ëª…ë ¹ì— ì•„ì´ì½˜ ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            # 5ì´ˆ ë™ì•ˆ ë²„íŠ¼ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ë°˜ë³µ íƒìƒ‰ (ì‹ ë¢°ì„± ìƒìŠ¹)
            found = click_icon(icon_name, confidence=0.8, timeout=5.0)
            if not found:
                push_msg(f"âš ï¸ 5ì´ˆ ë™ì•ˆ ê¸°ë‹¤ë ¸ì§€ë§Œ '{icon_name}' ë²„íŠ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return found

        elif cmd_type == "ICON_TYPE":
            raw = ":".join(parts[2:]) if len(parts) > 2 else ""
            text = raw[:-2] if raw.endswith("__") else raw
            if not text:
                push_msg("âŒ ICON_TYPE ëª…ë ¹ì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            push_msg(f"ğŸ” ì…ë ¥ íƒ€ê²Ÿ: '{text[:40]}'")
            return type_into_chatwindow(text)

    # 2. ì¼ë°˜ í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
    text = command
    if text.startswith("[ğŸ“±MOBILE]"):
        text = text.replace("[ğŸ“±MOBILE]", "").strip()

    # ğŸ“Œ 125% ë°°ìœ¨ í™˜ê²½ì˜ ì±„íŒ… ì…ë ¥ì°½ ì¢Œí‘œ
    click_x = int(l + w * 0.88) 
    click_y = int(t + h * 0.927)

    if DEBUG_IMAGE:
        try:
            shot = pyautogui.screenshot(region=(click_x-100, click_y-100, 200, 200))
            push_img(shot, f"ğŸ“Š í´ë¦­ ìœ„ì¹˜ ë””ë²„ê·¸ ({click_x}, {click_y})")
        except: pass

    # ì´ë™ ë° í¬ì»¤ìŠ¤ í™•ë³´ë¥¼ ìœ„í•œ í´ë¦­
    pyautogui.moveTo(click_x, click_y, duration=0.3)
    pyautogui.click()
    time.sleep(0.1)
    pyautogui.click() 
    time.sleep(0.3)

    # í…ìŠ¤íŠ¸ ì…ë ¥ ë° ì—”í„°
    pyperclip.copy(text)
    pyautogui.hotkey("ctrl", "a")
    time.sleep(0.1)
    pyautogui.press("backspace")
    time.sleep(0.1)
    pyautogui.hotkey("ctrl", "v")
    time.sleep(0.3)
    # 4. ì „ì†¡ ë²„íŠ¼(proceed) í´ë¦­ ì‹œë„ (ë˜ëŠ” ì—”í„°)
    if not click_icon("proceed", confidence=0.8, timeout=3.0):
        pyautogui.press("enter")
        # push_msg("âš ï¸ ì „ì†¡ ë²„íŠ¼(â†’) ëª» ì°¾ì•„ì„œ Enterë¡œ ì „ì†¡í•¨") # ë„ˆë¬´ ì¦ì€ ì•Œë¦¼ ë°©ì§€ ì›í•˜ì‹œë©´ ì£¼ì„
    
    return True

def inbound_loop():
    print("ğŸš€ [Inbound Thread] v3.4 ì‹œì‘")
    while True:
        try:
            box = read_mailbox()
            tasks = box.get("inbound", [])
            if tasks:
                box["inbound"] = []
                write_mailbox(box)
                for task in tasks: execute_brain_task(task)
        except Exception as e: print(f"Error: {e}")
        time.sleep(1)


# â”€â”€ Auto Watcher â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_auto_watch_active = False
_auto_watch_lock = threading.Lock()

# ê°ì‹œí•  ì•„ì´ì½˜ ëª©ë¡: (ì•„ì´ì½˜ì´ë¦„, í‘œì‹œë¼ë²¨, confidence)
# âš ï¸ proceedëŠ” ë¹„í™œì„±(grey) ìƒíƒœë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•´ confidence ë§¤ìš° ë†’ê²Œ ì„¤ì •
AUTO_ICONS = [
    ("accept_all",  "âœ… Accept all",   0.8),
    ("proceed",     "â¡ï¸ Proceed",      0.95),
    ("run",         "â–¶ï¸ Run",          0.8),
    ("scrolldown",  "ğŸ”½ Scroll Down",   0.8),
]

def find_color_buttons(img_pil):
    """auto_approver.pyì—ì„œ ê°€ì ¸ì˜¨ ìƒ‰ìƒ ê¸°ë°˜ ë²„íŠ¼ ê°ì§€ ë¡œì§"""
    if ndimage is None: return []
    try:
        img = np.array(img_pil)
        R, G, B = img[:, :, 0], img[:, :, 1], img[:, :, 2]
        mask_blue = (B > 130) & (B > R * 1.5) & (B > G * 1.1)
        mask_green = (G > 130) & (G > R * 1.2)
        mask_combined = mask_blue | mask_green
        labeled, _ = ndimage.label(mask_combined)
        objects = ndimage.find_objects(labeled)
        buttons = []
        for i, slices in enumerate(objects):
            if slices is None: continue
            sy, sx = slices
            h, w = sy.stop - sy.start, sx.stop - sx.start
            area = np.sum(labeled[slices] == (i + 1))
            if w < 40 or h < 20 or w > 350 or h > 80: continue
            if area < 350 or (w/h) < 1.1 or (w/h) > 7.0: continue
            # Solidity ì²´í¬: ì‚¬ê°í˜• ë©´ì  ëŒ€ë¹„ ì‹¤ì œ ìƒ‰ìƒì´ 60% ì´ìƒ ì±„ì›Œì ¸ì•¼ ë²„íŠ¼ìœ¼ë¡œ ì¸ì •
            if area / (w * h) < 0.60: continue
            buttons.append({"x": sx.start + w // 2, "y": sy.start + h // 2})
        return buttons
    except Exception: return []

_ocr_reader = None
_ocr_lock = threading.Lock()

# ë¬´ì‹œí•  UI í…ìŠ¤íŠ¸ ëª©ë¡ (ë¸”ë™ë¦¬ìŠ¤íŠ¸)
OCR_BLACKLIST = [
    "0 Files With Changes", "Review Changes", "Ask anything", "mention", 
    "workflows", "Fast", "Gemini 3 Flash", "Screen Reader Optimized", 
    "Antigravity - Settings", "Usage", "Thought for", "Open Agent Manager",
    "Running background command", "Relocate", "Cancel", "Good", "Bad", "Always run"
]

def get_local_ocr(img_pil):
    """EasyOCRì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë‚´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ëŠê¹€ ì—†ì´ ì „ë¬¸ ì¶”ì¶œ (í•œ/ì˜ ì§€ì›)"""
    global _ocr_reader
    try:
        import easyocr
        with _ocr_lock:
            if _ocr_reader is None:
                _ocr_reader = easyocr.Reader(['ko', 'en'])
        
        img_np = np.array(img_pil)
        # detail=1ë¡œ ì„¤ì •í•˜ì—¬ ì¢Œí‘œê°’(bbox)ê¹Œì§€ ê°€ì ¸ì˜´
        results = _ocr_reader.readtext(img_np, detail=1)
        
        if not results: return ""
        
        # 1. ìœ íš¨í•œ í…ìŠ¤íŠ¸ í•„í„°ë§
        valid_blocks = []
        for (bbox, text, conf) in results:
            text = text.strip()
            if len(text) < 2 or conf < 0.20: continue
            
            # ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
            if any(bl.lower() in text.lower() for bl in OCR_BLACKLIST): continue
            
            # ë¸”ë¡ì˜ ìƒë‹¨ yì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•´ ì €ì¥
            y_top = bbox[0][1]
            x_left = bbox[0][0]
            valid_blocks.append({'y': y_top, 'x': x_left, 'text': text})
            
        if not valid_blocks: return ""
        
        # 2. ìŠ¤ë§ˆíŠ¸ ë¬¸ì¥ ë³‘í•© (Yì¢Œí‘œê°€ ë¹„ìŠ·í•˜ë©´ ê°™ì€ ì¤„ë¡œ ì¸ì‹, ë„ˆë¬´ ë–¨ì–´ì ¸ ìˆì§€ ì•Šìœ¼ë©´ ì´ì–´ë¶™ì„)
        # ìš°ì„  Yì¢Œí‘œ ìˆœìœ¼ë¡œ ì •ë ¬
        valid_blocks.sort(key=lambda b: b['y'])
        
        lines = []
        if valid_blocks:
            current_line = valid_blocks[0]['text']
            last_y = valid_blocks[0]['y']
            
            for i in range(1, len(valid_blocks)):
                block = valid_blocks[i]
                # ì¤„ ë°”ë€œ íŒë‹¨ ê¸°ì¤€ (ê¸€ì ë†’ì´ì˜ ì•½ ì ˆë°˜ ì´ìƒ ì°¨ì´ë‚˜ë©´ ë‹¤ìŒ ì¤„)
                if block['y'] - last_y > 15: 
                    lines.append(current_line)
                    current_line = block['text']
                else:
                    # ê°™ì€ ì¤„ì´ë©´ ë„ì–´ì“°ê¸°ë¡œ ì´ì–´ë¶™ì„
                    current_line += " " + block['text']
                last_y = block['y']
            lines.append(current_line)
        
        # ì „ë¬¸ í•©ì¹˜ê¸°
        full_text = "\n".join(lines)
        # ì‚¬ì§„ê³¼ ë¶„ë¦¬í•˜ì—¬ ë”°ë¡œ ì „ì†¡í•˜ë¯€ë¡œ ê¸€ì ìˆ˜ ì œí•œì„ ë„‰ë„‰í•˜ê²Œ 2000ìë¡œ í™•ì¥
        return f"ğŸ“– **Full Text OCR ì „ë¬¸:**\n\n{full_text.strip()[:2000]}" 
    except Exception as e:
        return f"âš ï¸ OCR ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

get_gemini_ocr = get_local_ocr 

def send_chat_snapshot(caption="ğŸ“Š [Auto] ë³€í™” ê°ì§€"):
    """ì±„íŒ… ë³¸ë¬¸ë§Œ ì •ë°€ ìº¡ì²˜ + ë¦¬ëª¨ì»¨ ì¸ë¼ì¸ ë²„íŠ¼ ì „ì†¡ + ì§„ë‹¨ ì •ë³´ ì œê³µ"""
    hwnd, rect, _ = get_vscode_window_rect()
    if not rect: return
    l, t, r, b = rect
    w, h = r - l, b - t
    
    # ğŸ¯ ì´ë¯¸ì§€ ìº¡ì²˜ ì˜ì—­ ì •ë°€ ì¡°ì ˆ
    # 1. ì¢Œì¸¡ ì—¬ë°± ê±´ë„ˆë›°ê¸°: ì˜¤ë¥¸ìª½ 35% ì˜ì—­ ì¤‘ì—ì„œë„ 100px ë” ì˜¤ë¥¸ìª½ì—ì„œ ì‹œì‘ (ì‚¬ì´ë“œë°”/ë¼ì¸ë„˜ë²„ ì œê±°)
    chat_x = int(l + w * 0.65) + 100
    chat_w = int(w * 0.35) - 100
    
    # 2. ìƒí•˜ë‹¨ í—¤ë”/í‘¸í„° ê±´ë„ˆë›°ê¸°
    chat_y = t + 65 # í—¤ë” ì•½ 65px ë¬´ì‹œ
    chat_h = h - 65 - 200 # í•˜ë‹¨ ì…ë ¥ì°½/í‘¸í„° ì•½ 200px ë¬´ì‹œ (ë” ê°•í™”)
    
    if chat_w <= 0 or chat_h <= 0: return

    try:
        shot = pyautogui.screenshot(region=(chat_x, chat_y, chat_w, chat_h))
        
        # [DEBUG ì „ ì „ìš©] ë¡œì»¬ì— ìº¡ì²˜ë³¸ ì €ì¥í•˜ì—¬ í™•ì¸ ê°€ëŠ¥ì¼€ í•¨
        debug_dir = os.path.join(os.getcwd(), ".debug")
        os.makedirs(debug_dir, exist_ok=True)
        debug_path = os.path.join(debug_dir, "last_capture.png")
        shot.save(debug_path)

        ocr_text = get_gemini_ocr(shot)
        
        # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€ (ìº¡ì²˜ ì˜ì—­ ì¢Œí‘œ)
        debug_info = ""
        if "DEBUG" in caption or "Manual" in caption:
            debug_info = f"\nğŸ“ `X:{chat_x}, Y:{chat_y}, W:{chat_w}, H:{chat_h}`"
        
        photo_caption = f"{caption}{debug_info}"

        reply_markup = {
            "inline_keyboard": [
                [
                    {"text": "âœ… Accept All", "callback_data": "btn_accept"},
                    {"text": "â¡ï¸ Proceed", "callback_data": "btn_proceed"}
                ],
                [
                    {"text": "â–¶ï¸ Run", "callback_data": "btn_run"},
                    {"text": "ğŸ›‘ Stop", "callback_data": "btn_stop_agent"}
                ],
                [
                    {"text": "ğŸ“¸ Refresh", "callback_data": "btn_chat_refresh"}
                ]
            ]
        }

        buf = BytesIO()
        shot.save(buf, format="PNG")
        buf.seek(0)
        
        # 1. ì‚¬ì§„ ì „ì†¡ (ê¸°ë³¸ ì •ë³´ + ë²„íŠ¼)
        requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto", 
                      files={'photo': ( 'chat.png', buf, 'image/png')}, 
                      data={
                          'chat_id': int(CHAT_ID), 
                          'caption': photo_caption,
                          'reply_markup': json.dumps(reply_markup),
                          'parse_mode': 'Markdown'
                      }, 
                      timeout=15)
        
        # 2. OCR ë¦¬í¬íŠ¸ ë³„ë„ ì „ì†¡ (ë…ë¦½ëœ í…ìŠ¤íŠ¸ ë©”ì‹œì§€)
        if ocr_text and len(ocr_text.strip()) > 0:
            print(f"[*] Sending OCR report ({len(ocr_text)} chars)...")
            # MarkdownV2 ëŒ€ì‹  ì¼ë°˜ Markdownì„ ì“°ë˜, íŠ¹ìˆ˜ë¬¸ì ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„
            msg_res = requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
                        data={
                            'chat_id': int(CHAT_ID),
                            'text': ocr_text,
                            'parse_mode': 'Markdown'
                        }, timeout=15)
            
            if msg_res.status_code != 200:
                print(f"[!] Markdown OCR delivery failed ({msg_res.status_code}), retrying as plain text...")
                requests.post(f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
                            data={
                                'chat_id': int(CHAT_ID),
                                'text': ocr_text
                            }, timeout=15)
        else:
            print("[!] OCR text is empty, skipping message.")

        return shot
    except Exception as e: 
        print(f"Error in send_chat_snapshot: {e}")
        import traceback
        traceback.print_exc()
        return None

def auto_watcher_loop():
    """7ì´ˆë§ˆë‹¤ ê°ì‹œ, ë³€í™” ê°ì§€ ì‹œ ì¦‰ì‹œ ìŠ¤ëƒ…ìƒ·(ë²„íŠ¼ í¬í•¨) ì „ì†¡"""
    global _auto_watch_active
    COOLDOWN = 5.0 
    last_click: dict = {}
    
    # ë³€í™” ê°ì§€ìš© ë³€ìˆ˜
    prev_chat_thumb = None
    last_change_time = 0
    change_notified = True
    last_interval_snapshot = 0 # 1ë¶„ ê°„ê²© ìŠ¤ëƒ…ìƒ·ìš©

    while True:
        with _auto_watch_lock:
            active = _auto_watch_active
        if not active:
            time.sleep(1)
            continue

        hwnd, rect, _ = get_vscode_window_rect()
        if not rect:
            time.sleep(7)
            continue
        
        l, t, r, b = rect
        w, h = r - l, b - t

        # A. ì•„ì´ì½˜ ê°ì‹œ (ëª¨ì–‘ ì¸ì‹)
        for icon_name, label, conf in AUTO_ICONS:
            icon_path = os.path.join(ICON_DIR, f"icon_{icon_name}.png")
            if not os.path.exists(icon_path): continue
            now = time.time()
            if now - last_click.get(icon_name, 0) < COOLDOWN: continue
            try:
                pos = pyautogui.locateCenterOnScreen(icon_path, confidence=conf)
                if pos:
                    pyautogui.moveTo(pos, duration=0.15)
                    pyautogui.click()
                    last_click[icon_name] = time.time()
                    push_msg(f"ğŸ¤– [Auto] {label} ìë™ í´ë¦­")
                    time.sleep(0.3)
            except: pass

        # B. ìŠ¤ë§ˆíŠ¸ ë³€í™” ê°ì§€ (ìƒˆ ë©”ì‹œì§€ ì•Œë¦¼)
        try:
            chat_x, chat_w = int(l + w * 0.65), int(w * 0.35)
            # ì•„ì£¼ ì‘ì€ ì¸ë„¤ì¼ë¡œ ë¹„êµ (ì†ë„/ë©”ëª¨ë¦¬ ì ˆì•½)
            current_chat = pyautogui.screenshot(region=(chat_x, t, chat_w, h))
            curr_thumb = np.array(current_chat.resize((50, 100)).convert('L'))
            
            if prev_chat_thumb is not None:
                diff = np.mean(np.abs(curr_thumb.astype(float) - prev_chat_thumb.astype(float)))
                # ì°¨ì´ê°€ ì¼ì • ìˆ˜ì¤€(ë°°ê²½ ë…¸ì´ì¦ˆ ì´ìƒ)ì´ë©´ ë³€í™”ë¡œ ê°„ì£¼
                if diff > 1.5: 
                    last_change_time = time.time()
                    change_notified = False
                
                # ë³€í™”ê°€ ë©ˆì¶˜ ì§€ 3ì´ˆê°€ ì§€ë‚¬ê³  ì•„ì§ ì•Œë¦¼ ì „ì´ë¼ë©´ ì „ì†¡
                if not change_notified and (time.time() - last_change_time > 3.0):
                    send_chat_snapshot("ğŸ”” [Auto] AIê°€ ìƒˆë¡œìš´ ë‚´ìš©ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.")
                    change_notified = True
            
            prev_chat_thumb = curr_thumb
        except: pass

        # C. ìƒ‰ìƒ ê¸°ë°˜ ìŠ¹ì¸ ë²„íŠ¼ ê°ì§€ (Approver í†µí•©)
        try:
            # VS Code ì˜ì—­ ìº¡ì²˜ (ì—ë””í„° ì™¼ìª½ 40%ë¥¼ ê±´ë„ˆëœœìœ¼ë¡œì¨ ì˜¤ì‘ë™ ë°©ì§€)
            zone_l, zone_t = max(0, l + int(w*0.40)), max(0, t + 40)
            zone_w, zone_h = min(int(w*0.55), pyautogui.size()[0]-zone_l), min(h-100, pyautogui.size()[1]-zone_t)
            if zone_w > 0 and zone_h > 0:
                shot = pyautogui.screenshot(region=(zone_l, zone_t, zone_w, zone_h))
                c_btns = find_color_buttons(shot)
                if c_btns:
                    top_b = [btn for btn in c_btns if btn["y"] < zone_h * 0.35]
                    target = top_b[0] if top_b else sorted(c_btns, key=lambda b: b["y"], reverse=True)[0]
                    rx, ry = zone_l + target["x"], zone_t + target["y"]
                    pyautogui.moveTo(rx, ry, duration=0.15)
                    pyautogui.click()
                    push_msg("ğŸ¤– [Auto] ìƒ‰ìƒ ê°ì§€ ìŠ¹ì¸ ë²„íŠ¼ í´ë¦­")
                    time.sleep(0.3)
        except: pass

        # D. ë§ˆìš°ìŠ¤ íœ  ìŠ¤í¬ë¡¤ ë‹¤ìš´ (ì±„íŒ… ë”°ë¼ê°€ê¸°)
        try:
            sx, sy = int(l + w * 0.85), int(t + h * 0.5)
            pyautogui.moveTo(sx, sy)
            pyautogui.scroll(-50)
        except: pass

        # E. 1ë¶„ ê°„ê²© ì •ê¸° ìŠ¤ëƒ…ìƒ· (ì‚¬ìš©ì ìš”ì²­)
        now = time.time()
        if now - last_interval_snapshot > 60:
            send_chat_snapshot("â²ï¸ [Auto] 1ë¶„ ê°„ê²© ì •ê¸° ìŠ¤ëƒ…ìƒ·")
            last_interval_snapshot = now

        time.sleep(1) # ë£¨í”„ ê³¼ë¶€í•˜ ë°©ì§€

if __name__ == "__main__":
    threading.Thread(target=inbound_loop, daemon=True).start()
    threading.Thread(target=auto_watcher_loop, daemon=True).start()
    print("ğŸ¤– Auto Watcher (ì•„ì´ì½˜+ìƒ‰ìƒ) ìŠ¤ë ˆë“œ ëŒ€ê¸° ì¤‘ (/auto ëª…ë ¹ìœ¼ë¡œ í™œì„±í™”)")
    try:
        while True: time.sleep(1)
    except KeyboardInterrupt: pass
