import os
import sys
import time
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import easyocr
import cv2

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€ (agent_brain ì„í¬íŠ¸ìš©)
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from agent_brain import get_vscode_window_rect, clean_ocr_text, OCR_BLACKLIST

def run_ocr_tuning():
    print("ğŸ§ª [OCR Tuner] ì‹œìŠ¤í…œ ì‹œì‘...")
    
    # 1. ìœˆë„ìš° ì°¾ê¸° ë° ìº¡ì²˜
    hwnd, rect, _ = get_vscode_window_rect()
    if not rect:
        print("âŒ VS Code ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    l, t, r, b = rect
    w, h = r - l, b - t
    
    # agent_brainê³¼ ë™ì¼í•œ í¬ë¡­ ë¡œì§ ì ìš©
    # h_crop: í—¤ë”(65), í•˜ë‹¨(200), l_crop: ì™¼ìª½(100)
    chat_x, chat_y = l + 100, t + 65
    chat_w, chat_h = w - 100, h - 65 - 200
    
    print(f"ğŸ“¸ ìº¡ì²˜ ì˜ì—­: X={chat_x}, Y={chat_y}, W={chat_w}, H={chat_h}")
    import pyautogui
    img_pil = pyautogui.screenshot(region=(chat_x, chat_y, chat_w, chat_h))
    
    # ë””ë²„ê·¸ìš© ì›ë³¸ ì €ì¥
    if not os.path.exists(".debug"): os.makedirs(".debug")
    img_pil.save(".debug/tuner_target.png")
    
    # 2. OCR ì—”ì§„ ì´ˆê¸°í™”
    print("[*] EasyOCR ë¡œë“œ ì¤‘...")
    reader = easyocr.Reader(['ko', 'en'])
    
    # 3. í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„° ì¡°í•© ì„¤ì •
    # (scale, binarize, contrast)
    tests = [
        {"scale": 1.0, "binarize": False, "desc": "Original"},
        {"scale": 1.5, "binarize": False, "desc": "1.5x Scaling"},
        {"scale": 1.5, "binarize": True, "desc": "1.5x + Adaptive Binarization"},
        {"scale": 2.0, "binarize": False, "desc": "2.0x Scaling"}
    ]
    
    results_summary = []

    for test in tests:
        scale = test["scale"]
        do_bin = test["binarize"]
        desc = test["desc"]
        
        print(f"\n--- ğŸ§ª Test: {desc} ---")
        
        # ì „ì²˜ë¦¬
        w_new, h_new = int(chat_w * scale), int(chat_h * scale)
        img_work = img_pil.resize((w_new, h_new), Image.Resampling.LANCZOS)
        
        if do_bin:
            gray = np.array(img_work.convert('L'))
            img_np = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        else:
            img_np = np.array(img_work.convert('L'))
            
        # OCR ì‹¤í–‰
        t1 = time.time()
        results = reader.readtext(img_np, detail=1)
        t2 = time.time()
        
        # ê²°ê³¼ ë¶„ì„
        valid_text = []
        conf_sum = 0
        for (bbox, text, conf) in results:
            if conf > 0.15:
                valid_text.append(text)
                conf_sum += conf
        
        avg_conf = conf_sum / len(valid_text) if valid_text else 0
        print(f"â±ï¸ ì‹œê°„: {t2-t1:.2f}s | ğŸ§© ë¸”ë¡ ìˆ˜: {len(valid_text)} | ğŸ¯ í‰ê·  ì‹ ë¢°ë„: {avg_conf:.2f}")
        
        full_result = " ".join(valid_text)
        corrected = clean_ocr_text(full_result)
        
        print(f"ğŸ“ ê²°ê³¼ ìš”ì•½: {corrected[:100]}...")
        
        # ì‹œê°í™” ì´ë¯¸ì§€ ìƒì„± (ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë§Œ ìƒì„¸ ì €ì¥)
        if scale == 1.5 and not do_bin:
            vis_img = Image.fromarray(img_np).convert("RGB")
            draw = ImageDraw.Draw(vis_img)
            for (bbox, text, conf) in results:
                pts = [tuple(p) for p in bbox]
                draw.polygon(pts, outline="red")
            vis_img.save(".debug/tuner_visualization.png")

    print("\nâœ… íŠœë‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ. '.debug/tuner_target.png'ì™€ 'tuner_visualization.png'ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    run_ocr_tuning()
